{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(594142, 6)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "讀csv資料\n",
    "\"\"\"\n",
    "data_path = './Data/'\n",
    "df_train = pd.read_csv(data_path+'train_offline.csv')\n",
    "df_test = pd.read_csv(data_path+'test_offline.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_id</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merchant_id</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coupon_id</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Discount_rate</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Distance</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Date_received</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Date</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index        0\n",
       "0        User_id    int64\n",
       "1    Merchant_id    int64\n",
       "2      Coupon_id  float64\n",
       "3  Discount_rate   object\n",
       "4       Distance  float64\n",
       "5  Date_received  float64\n",
       "6           Date  float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test 沒有date 欄位\n",
    "df_train.columns\n",
    "df_test.columns\n",
    "'''\n",
    "\n",
    "'''\n",
    "#ids = ['User_id', 'Coupon_id','Merchant_id']\n",
    "#df = df_train.drop(['User_id', 'Coupon_id','Merchant_id'] , axis=1)\n",
    "df = df_train\n",
    "df.head()\n",
    "\n",
    "dtype_df = df.dtypes.reset_index() \n",
    "dtype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:83: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "def convertRate(row):\n",
    "    \"\"\"Convert discount to rate\"\"\"\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return 1.0 - float(rows[1])/float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "    \n",
    "def getDiscountType(row):\n",
    "    if row == 'null':\n",
    "        return 'null'\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def getDiscountMan(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getDiscountJian(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def getWeekday(row):\n",
    "    row = str(row)\n",
    "    if(row == 'nan'):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return date(int(row[0:4]), int(row[4:6]), int(row[6:8])).weekday() + 1\n",
    "\n",
    "def getreceived(row):\n",
    "    if(row == 'nan'):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def processData(df):\n",
    "    \n",
    "    # convert distance\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    df.loc[df.Discount_rate.isna(), \"Discount_rate\"] = 1.0\n",
    "    \n",
    "    # convert discunt_rate\n",
    "    df['float_discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "    \n",
    "    discount_mean = df.groupby(['User_id'])['float_discount_rate'].mean().reset_index()\n",
    "    discount_mean.rename(columns={'float_discount_rate':'discount_mean'},inplace=True)\n",
    "    df = pd.merge(df,discount_mean, how='left', on=['User_id'])\n",
    "\n",
    "    #平均距離( (x * 500 公尺), 0 表示低於 500 公尺, 10 表示大於 5 公里。)\n",
    "    Distance_mean = df.groupby(['Coupon_id'])['Distance'].mean().reset_index()\n",
    "    Distance_mean.rename(columns={'Distance':'Distance_mean'},inplace=True)\n",
    "    df = pd.merge(df,Distance_mean, how='left', on=['Coupon_id'])\n",
    "    df['Distance_mean'] = df['Distance_mean']\n",
    "    df['Distance_mean'] = df['Distance_mean'].fillna(99)\n",
    "    \n",
    "     #距離前兩大 0跟10\n",
    "    df['Distance_type'] = df['Distance_mean'].apply(lambda x : 1 if x in[0,10] else 0 )\n",
    "    #最大距離\n",
    "    Distance_max = df.groupby(['Coupon_id'])['Distance'].max().reset_index()\n",
    "    Distance_max.rename(columns={'Distance':'Distance_max'},inplace=True)\n",
    "    df = pd.merge(df,Distance_max, how='left', on=['Coupon_id'])\n",
    "    df['Distance_max'] = df['Distance_max'].fillna(99)\n",
    "    #計次_使用者_取折價日期\n",
    "    count_df = df.groupby(['User_id'])['Date_received'].agg({'Date_received_Count':'size'}).reset_index()\n",
    "    df = pd.merge(df, count_df, on=['User_id'], how='left')\n",
    "    df['Date_received_Count'] = df['Date_received_Count'].fillna(0)\n",
    "    df['Date_received_Count_type'] = df['Date_received_Count'].apply(lambda x : 1 if x < 3 else 0 )\n",
    "    df['get_Date_received'] = df['Date_received'].astype('str').apply(getreceived)\n",
    "\n",
    "    \n",
    "    count_df = df.groupby(['Coupon_id'])['Date_received'].agg({'Date_received_Count2':'size'}).reset_index()\n",
    "    df = pd.merge(df, count_df, on=['Coupon_id'], how='left')\n",
    "    \n",
    "    \n",
    "    \n",
    "    count_df = df.groupby(['Merchant_id'])['Coupon_id'].agg({'Coupon_id_Count':'size'}).reset_index()\n",
    "    df = pd.merge(df, count_df, on=['Merchant_id'], how='left')\n",
    "    df['Coupon_id_Count'] = df['Coupon_id_Count'].fillna(0)\n",
    "    df['Coupon_id_Count_type'] = df['Coupon_id_Count'].apply(lambda x : 1 if x <2 else 0 )\n",
    "    \n",
    "    # weekday_type :  周5和周日为1，其他为0\n",
    "    df['weekday'] = df['Date_received'].astype(str).apply(getWeekday)\n",
    "    df['weekday_type'] = df['weekday'].apply(lambda x : 1 if x in [5,7] else 0 )\n",
    "    \n",
    "    df['MID_CID'] = (df['Merchant_id'] + df['Coupon_id'])/2\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "df = processData(df)\n",
    "df_test = processData(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef testP(df):\\n    \\n    return df\\n\\ndf = testP(df)\\ndf_test = testP(df_test)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def testP(df):\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = testP(df)\n",
    "df_test = testP(df_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label(row):\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df[\"label\"] = df.apply(label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>float_discount_rate</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>...</th>\n",
       "      <th>Date_received_Count</th>\n",
       "      <th>Date_received_Count_type</th>\n",
       "      <th>get_Date_received</th>\n",
       "      <th>Date_received_Count2</th>\n",
       "      <th>Coupon_id_Count</th>\n",
       "      <th>Coupon_id_Count_type</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>MID_CID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5611.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46676.0</td>\n",
       "      <td>137054</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5495.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26035.0</td>\n",
       "      <td>137054</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN             1       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "\n",
       "         Date  float_discount_rate  discount_man  discount_jian  ...  \\\n",
       "0  20160217.0                 1.00             0              0  ...   \n",
       "1         NaN                 0.95            20              1  ...   \n",
       "2         NaN                 0.95            20              1  ...   \n",
       "3         NaN                 0.90           200             20  ...   \n",
       "4         NaN                 0.90           200             20  ...   \n",
       "\n",
       "   Date_received_Count  Date_received_Count_type  get_Date_received  \\\n",
       "0                    3                         0                  0   \n",
       "1                    3                         0                  1   \n",
       "2                    3                         0                  1   \n",
       "3                    1                         1                  1   \n",
       "4                    1                         1                  1   \n",
       "\n",
       "   Date_received_Count2  Coupon_id_Count  Coupon_id_Count_type  weekday  \\\n",
       "0                   NaN               45                     0      NaN   \n",
       "1                  24.0               45                     0      3.0   \n",
       "2                   8.0               45                     0      6.0   \n",
       "3               46676.0           137054                     0      5.0   \n",
       "4               26035.0           137054                     0      5.0   \n",
       "\n",
       "   weekday_type  MID_CID  label  \n",
       "0             0      NaN     -1  \n",
       "1             0   5611.5      0  \n",
       "2             0   1855.0      0  \n",
       "3             1   5495.5      0  \n",
       "4             1   7666.0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#df.head()\n",
    "#df.groupby(['label'])['Coupon_id_Count'].value_counts() #7610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  Merchant_id\n",
       "-1     2934           21884\n",
       "       5341           19656\n",
       "       3381           14273\n",
       "       3532           13940\n",
       "       6485           11774\n",
       "       1469            9287\n",
       "       760             7711\n",
       "       6901            7524\n",
       "       2436            7084\n",
       "       450             6992\n",
       "       4142            6744\n",
       "       7555            6019\n",
       "       2099            4785\n",
       "       1433            4583\n",
       "       5591            4010\n",
       "       1379            3957\n",
       "       1941            3897\n",
       "       2970            3807\n",
       "       7717            3762\n",
       "       3284            3664\n",
       "       3710            3401\n",
       "       3621            3130\n",
       "       7974            3080\n",
       "       8181            2916\n",
       "       1945            2801\n",
       "       1169            2662\n",
       "       3786            2555\n",
       "       1125            2453\n",
       "       1080            2361\n",
       "       7113            2325\n",
       "                      ...  \n",
       " 1     8508               1\n",
       "       8534               1\n",
       "       8547               1\n",
       "       8563               1\n",
       "       8585               1\n",
       "       8588               1\n",
       "       8597               1\n",
       "       8607               1\n",
       "       8613               1\n",
       "       8640               1\n",
       "       8643               1\n",
       "       8655               1\n",
       "       8664               1\n",
       "       8673               1\n",
       "       8674               1\n",
       "       8700               1\n",
       "       8702               1\n",
       "       8721               1\n",
       "       8722               1\n",
       "       8724               1\n",
       "       8733               1\n",
       "       8734               1\n",
       "       8736               1\n",
       "       8764               1\n",
       "       8807               1\n",
       "       8824               1\n",
       "       8830               1\n",
       "       8831               1\n",
       "       8842               1\n",
       "       8850               1\n",
       "Name: Merchant_id, Length: 11594, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_Y.value_counts()\n",
    "df.groupby(['label'])['Merchant_id'].value_counts() #7610\n",
    "#df['Merchant_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 667753, #positive: 32472\n",
      "Valid size: 79216, #positive: 3832\n"
     ]
    }
   ],
   "source": [
    "def split_train_valid(row, date_cut=\"20160416\"):\n",
    "    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "    return is_train\n",
    "\n",
    "df_x =df[df['label'] != -1].copy()\n",
    "df_x[\"is_train\"] = df_x[\"Date_received\"].apply(split_train_valid)\n",
    "train = df_x[df_x[\"is_train\"]]\n",
    "valid = df_x[~df_x[\"is_train\"]]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "print(\"Train size: {}, #positive: {}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(valid), valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['Distance','float_discount_rate','discount_man','discount_jian','discount_type','Distance_mean','Distance_max','Date_received_Count','weekday','weekday_type','Date_received_Count_type','Distance_type','Date_received_Count2','Coupon_id_Count','Coupon_id_Count_type','MID_CID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Distance', 'float_discount_rate', 'discount_man', 'discount_jian', 'discount_type', 'Distance_mean', 'Distance_max', 'Date_received_Count', 'weekday', 'weekday_type', 'Date_received_Count_type', 'Distance_type', 'Date_received_Count2', 'Coupon_id_Count', 'Coupon_id_Count_type', 'MID_CID']\n"
     ]
    }
   ],
   "source": [
    "predictors = feature\n",
    "print(predictors)\n",
    "\n",
    "def check_model(data, predictors):\n",
    "    \n",
    "    classifier = lambda: SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', StandardScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'en__alpha': [ 0.001, 0.01, 0.1],\n",
    "        'en__l1_ratio': [ 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  3.8min finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = check_model(train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = model.predict_proba(valid[predictors])\n",
    "valid1 = valid.copy()\n",
    "valid1['pred_prob'] = y_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.8341, Accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=y_valid_pred[:,1])\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=y_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.4f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594142, 23)\n",
      "(306313, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "targetset = df_test.copy()\n",
    "print(targetset.shape)\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset[predictors].copy()\n",
    "\n",
    "y_test_pred = model.predict_proba(testset[predictors])\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = y_test_pred[:, 1]\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n"
     ]
    }
   ],
   "source": [
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.049696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.048621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.061314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.046685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.032748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.049696\n",
       "1  1000020_8192_20160513  0.048621\n",
       "2  1000065_1455_20160527  0.061314\n",
       "3  1000085_8067_20160513  0.046685\n",
       "4  1000086_2418_20160613  0.032748"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv('submit.csv', index=False)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
